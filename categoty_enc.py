import pandas as pd
import numpy as np
import lightgbm as lgb
#import xgboost as xgb
from scipy.sparse import vstack, csr_matrix, save_npz, load_npz
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.neural_network import MLPRegressor
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from keras.models import Sequential
from keras.layers import Dense, Embedding
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

from dtypes import dtypes

import time



cat_columns = [key for key, value in dtypes.items() if value is 'category']
cat_types = {key: value for key, value in dtypes.items() if value is 'category'}
cat_columns.remove('MachineIdentifier')
cat_types.pop('MachineIdentifier', None)
# cat_columns.remove('HasDetections')

# print(cat_types)
# exit()

print('Load category features')
train = pd.read_csv('train.csv', dtype=cat_types, low_memory=True, nrows=100000)
# exit()
test  = pd.read_csv('test.csv',  dtype=cat_types, low_memory=True, nrows=100000)

print('Transform category features')

for usecol in cat_columns:
    train[usecol] = train[usecol].astype('str')
    test[usecol] = test[usecol].astype('str')
    
    #Fit LabelEncoder
    le = LabelEncoder().fit(
            np.unique(train[usecol].unique().tolist()+
                      test[usecol].unique().tolist()))

    #At the end 0 will be used for dropped values
    train[usecol] = le.transform(train[usecol])+1
    test[usecol]  = le.transform(test[usecol])+1

    agg_tr = (train
              .groupby([usecol])
              .aggregate({'MachineIdentifier':'count'})
              .reset_index()
              .rename({'MachineIdentifier':'Train'}, axis=1))
    agg_te = (test
              .groupby([usecol])
              .aggregate({'MachineIdentifier':'count'})
              .reset_index()
              .rename({'MachineIdentifier':'Test'}, axis=1))

    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)
    #Select values with more than 1000 observations
    agg = agg[(agg['Train'] > 100)].reset_index(drop=True)
    agg['Total'] = agg['Train'] + agg['Test']
    #Drop unbalanced values
    agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]
    agg[usecol+'Copy'] = agg[usecol]

    train[usecol] = (pd.merge(train[[usecol]], 
                              agg[[usecol, usecol+'Copy']], 
                              on=usecol, how='left')[usecol+'Copy']
                     .replace(np.nan, 0).astype('int').astype('category'))

    test[usecol]  = (pd.merge(test[[usecol]], 
                              agg[[usecol, usecol+'Copy']], 
                              on=usecol, how='left')[usecol+'Copy']
                     .replace(np.nan, 0).astype('int').astype('category'))

    del le, agg_tr, agg_te, agg, usecol
    gc.collect()

train = np.array(train)  
np.save('train_np_x', train)  
test = np.array(test)  
np.save('test_np_x', test)  
exit()

# print('SAVE TEST DF')
# test.to_csv('test_df.csv')
# del test
# gc.collect()

# print('SAVE TRAIN DF')
# train.to_csv('train_df.csv')
print('LOAD TRAIN DF')
# train = pd.read_csv('train_df.csv', low_memory=True)

# print('Transform train pandas to numpy.\n')  
# train_y = np.array(train['HasDetections'])  
# np.save('train_ynp', train_y)    
# train_x = np.array(train[train.columns.tolist()[1:-1]], dtype=np.float32)
# train_x = train[train.columns.tolist()[1:-1]].to_numpy()
# np.save('train_x_labeled.np', train_x)

model = Sequential()
model.add(Dense(64, input_dim=82, activation='relu'))
# model.add(Dense(128, activation='relu'))
# model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])


train_count = 8921483
test_count = 7853253
# N = 2973827
episodes = 12
N = int(train_count / episodes)
M = 2 * N
print('step = ', N)
results = np.zeros(test_count)
for episode in range(episodes):
    print('start episode - {}/{}'.format(episode+1, episodes))
    print('load numpy arrays')
    print(time.gmtime())
    train_x = np.load('train_x_labeled.np.npy')
    train_y = np.load('train_ynp.npy')
    # print(train_x.shape)
    print(train_x[2,:])
    exit()

    idx = np.random.randint(train_count, size=M)
    train_x_part = train_x[idx,:]
    train_y_part = train_y[idx]

    # start = N*episode
    # end = start + N
    # train_x_part = train_x[start:end,:]
    # train_y_part = train_y[start:end]

    del train_x, train_y
    gc.collect()

    # import pickle
    print('start training')
    print(time.gmtime())
    # model = RandomForestClassifier(n_estimators=100)
    # model = model.fit(train_x_part, train_y_part)

    # model = Sequential()
    # model.add(Dense(64, input_dim=train_x.shape[1], activation='relu'))
    # model.add(Dense(64, activation='relu'))
    # model.add(Dense(32, activation='relu'))
    # model.add(Dense(1, activation='sigmoid'))
    # model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
    model.fit(train_x_part, train_y_part, epochs=10, batch_size=32)

    # pickle.dump(clf, open('random_forest.mdl', 'wb'))
    # clf = pickle.load(open('random_forest.mdl', 'rb'))

    del train_x_part, train_y_part
    gc.collect()

    # test = pd.read_csv('test_df.csv', low_memory=True)
    # columns = list(dtypes.keys())
    # columns.remove('MachineIdentifier')
    # columns.remove('HasDetections')
    # print(columns)
    # exit()
    # test_x = test[columns].to_numpy()
    # np.save('test_x_labeled.np', test_x)
    # exit()
    # del test_x
    # gc.collect()
    test_x = np.load('test_x_labeled.np.npy')
    fkck = np.zeros((test_x.shape[0], 1))
    test_x = np.hstack((fkck, test_x))

    print('start prediction')
    print(time.gmtime())
    results += model.predict(test_x, batch_size=32)[:,0]
    # results += model.predict(test_x)
    print(results.shape)
    np.save('results', results)
    # accuracy = roc_auc_score(train_y, predictions)
    # print('accuracy: ', accuracy)

    del test_x
    # del model
    gc.collect()


submission = pd.read_csv('sample_submission.csv')
submission['HasDetections'] = results/ episodes
submission.to_csv('tree_label_submission.csv', index=False)

print('\nDone.')