import pandas as pd
import numpy as np
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from dtypes import dtypes
import time
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Embedding

cat_columns = [key for key, value in dtypes.items() if value is 'category']
cat_types = {key: value for key, value in dtypes.items() if value is 'category'}
cat_columns.remove('MachineIdentifier')
cat_types.pop('MachineIdentifier', None)
# cat_columns.remove('HasDetections')

# print(cat_types)
# exit()

print('Load category features')
train = pd.read_csv('train.csv', dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)
# exit()
test  = pd.read_csv('test.csv',  dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)

print('Transform category features')
col = 1
total_cols = len(cat_columns)

train = train.replace(np.nan, 0)
test = test.replace(np.nan, 0)

for usecol in cat_columns:
    print('column {}/{}'.format(col, total_cols))
    col+=1
    train[usecol] = train[usecol].astype('str')
    test[usecol] = test[usecol].astype('str')
    
    #Fit LabelEncoder
    le = LabelEncoder().fit(
            np.unique(train[usecol].unique().tolist()+
                      test[usecol].unique().tolist()))

    #At the end 0 will be used for dropped values
    train[usecol] = le.transform(train[usecol]) + 1
    test[usecol]  = le.transform(test[usecol]) + 1

    # agg_tr = (train
    #           .groupby([usecol])
    #           .aggregate({'MachineIdentifier':'count'})
    #           .reset_index()
    #           .rename({'MachineIdentifier':'Train'}, axis=1))
    # agg_te = (test
    #           .groupby([usecol])
    #           .aggregate({'MachineIdentifier':'count'})
    #           .reset_index()
    #           .rename({'MachineIdentifier':'Test'}, axis=1))

    # agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)
    #Select values with more than 1000 observations
    # agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)
    # agg['Total'] = agg['Train'] + agg['Test']
    #Drop unbalanced values
    # agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]
    # agg[usecol+'Copy'] = agg[usecol]

    # train[usecol] = (pd.merge(train[[usecol]], 
    #                           agg[[usecol, usecol+'Copy']], 
    #                           on=usecol, how='left')[usecol+'Copy']
    #                  .replace(np.nan, 0).astype('int').astype('category'))

    # test[usecol]  = (pd.merge(test[[usecol]], 
    #                           agg[[usecol, usecol+'Copy']], 
    #                           on=usecol, how='left')[usecol+'Copy']
    #                  .replace(np.nan, 0).astype('int').astype('category'))

    # del le, agg_tr, agg_te, agg, usecol
    del le, usecol
    gc.collect()

print('test.shape: ', test.shape)
test = np.array(test, dtype=np.int16)  
np.save('test_cat_np_x', test)  
del test
gc.collect()

print('train.shape: ', train.shape)
train = np.array(train, dtype=np.int16)  
np.save('train_cat_np_x', train)  

