import pandas as pd
import numpy as np
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from dtypes import dtypes
import time
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Embedding

cat_columns = [key for key, value in dtypes.items() if value is 'category']
cat_types = {key: value for key, value in dtypes.items() if value is 'category'}
cat_columns.remove('MachineIdentifier')
cat_types.pop('MachineIdentifier', None)
# cat_columns.remove('HasDetections')

# print(cat_types)
# exit()

print('Load category features')
train = pd.read_csv('train.csv', dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)
# exit()
test  = pd.read_csv('test.csv',  dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)

print('Transform category features')
col = 1
total_cols = len(cat_columns)


for usecol in cat_columns:
    print('column {}/{}'.format(col, total_cols))
    col+=1
    train[usecol] = train[usecol].astype('str')
    test[usecol] = test[usecol].astype('str')
    
    #Fit LabelEncoder
    le = LabelEncoder().fit(
            np.unique(train[usecol].unique().tolist()+
                      test[usecol].unique().tolist()))

    #At the end 0 will be used for dropped values
    train[usecol] = le.transform(train[usecol]) + 1
    test[usecol]  = le.transform(test[usecol]) + 1


    # categories_count = train[usecol].max()
    # if test[usecol].max() > categories_count:
    #     categories_count = test[usecol].max()

    # print('max code in {} col are {}'.format(usecol, categories_count))

    agg_tr = (train
              .groupby([usecol])
              .aggregate({'MachineIdentifier':'count'})
              .reset_index()
              .rename({'MachineIdentifier':'Train'}, axis=1))
    agg_te = (test
              .groupby([usecol])
              .aggregate({'MachineIdentifier':'count'})
              .reset_index()
              .rename({'MachineIdentifier':'Test'}, axis=1))

    agg = pd.merge(agg_tr, agg_te, on=usecol, how='outer').replace(np.nan, 0)
    #Select values with more than 1000 observations
    agg = agg[(agg['Train'] > 1000)].reset_index(drop=True)
    agg['Total'] = agg['Train'] + agg['Test']
    #Drop unbalanced values
    agg = agg[(agg['Train'] / agg['Total'] > 0.2) & (agg['Train'] / agg['Total'] < 0.8)]
    agg[usecol+'Copy'] = agg[usecol]

    train[usecol] = (pd.merge(train[[usecol]], 
                              agg[[usecol, usecol+'Copy']], 
                              on=usecol, how='left')[usecol+'Copy']
                     .replace(np.nan, 0).astype('int').astype('category'))

    test[usecol]  = (pd.merge(test[[usecol]], 
                              agg[[usecol, usecol+'Copy']], 
                              on=usecol, how='left')[usecol+'Copy']
                     .replace(np.nan, 0).astype('int').astype('category'))

    # model = Sequential()
    # vector_size = 2
    # if categories_count > 20 and categories_count <= 100:
    #     vector_size = 10
    # if categories_count > 100 and categories_count <= 1000:
    #     vector_size = 20
    # if categories_count > 1000:
    #     vector_size = 30

    # model.add(Embedding(categories_count, vector_size, input_length=1))
    # model.compile('rmsprop', 'mse')

    # train_part = np.array(train[usecol], dtype=np.int16)  
    # model.fit(train_part, train_part, batch_size=32)
    # train_array = model.predict(train_part, batch_size=32)
    # print('train_array.shape: ', train_array.shape)
    # print(train_array[0, :, :])
    # filename = 'train_' + usecol
    # np.save(filename, train_array) 

    # del train_part, train_array
    # gc.collect()

    # test_part = np.array(test[usecol], dtype=np.int16)  
    # model.fit(test_part, test_part, batch_size=32)
    # test_array = model.predict(test_part, batch_size=32)
    # print('test_array.shape: ', test_array.shape)
    # filename = 'test_' + usecol
    # np.save(filename, test_array)  

    # del test_part, test_array, model
    # gc.collect()
    del le, agg_tr, agg_te, agg, usecol
    gc.collect()
    # print('column {}/{}'.format(col, total_cols))
    # exit()

print('test.shape: ', test.shape)
test = np.array(test, dtype=np.int16)  
np.save('test_cat_np_x', test)  
del test
gc.collect()

print('train.shape: ', train.shape)
train = np.array(train, dtype=np.int16)  
np.save('train_cat_np_x', train)  

