import pandas as pd
import numpy as np
import lightgbm as lgb
#import xgboost as xgb
from scipy.sparse import vstack, csr_matrix, save_npz, load_npz
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.neural_network import MLPRegressor
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from keras.models import Sequential, Model
from keras.layers import Dense, Embedding, Input, Reshape, Concatenate
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score

from dtypes import dtypes

import time

print('load data')
N = 3000000
train_cat = np.load('train_cat_np_x_2.npy')[:]
train_num = np.load('train_num_np_x.npy')[:]
train_y = np.load('train_num_np_y.npy')[:]
test_cat = np.load('test_cat_np_x_2.npy')[:]
test_num = np.load('test_num_np_x.npy')[:]

# print(train_cat)
# print(train_num)
# print(train_y)
# exit()

inputs = []
embeddings = []
train_x = []
test_x = []

categories_count = train_cat.max()
print(categories_count)
print('build net')
vector_size = 200

input_layer = Input(shape=(29,))
embedding = Embedding(categories_count, vector_size, input_length=29)(input_layer)
embedding = Reshape(target_shape=(vector_size*29,))(embedding)

embedding = Dense(64, activation='relu')(embedding)

inputs.append(input_layer)
embeddings.append(embedding)
train_x.append(train_cat)

input_layer = Input(shape=(train_num.shape[1],))
embedding = Dense(16, activation='relu')(input_layer)
inputs.append(input_layer)
embeddings.append(embedding)
train_x.append(train_num)
# NUMERIC
x = Concatenate()(embeddings)
x = Dense(12, activation='relu')(x)
x = Dense(8, activation='relu')(x)
x = Dense(4, activation='relu')(x)
# x = Dense(10, activation='relu')(x)
output = Dense(1, activation='sigmoid')(x)
model = Model(inputs, output)
model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])
# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(train_x, train_y, batch_size=512, epochs=50)

test_x.append(test_cat)
test_x.append(test_num)
results = model.predict(test_x, batch_size=256)[:,0]
submission = pd.read_csv('sample_submission.csv')
submission['HasDetections'] = results
submission.to_csv('nn_embedding_submission.csv', index=False)
print('Done.')
exit()


train_count = 8921483
test_count = 7853253
# N = 2973827
episodes = 12
N = int(train_count / episodes)
M = 2 * N
print('step = ', N)
results = np.zeros(test_count)
for episode in range(episodes):
    print('start episode - {}/{}'.format(episode+1, episodes))
    print('load numpy arrays')
    print(time.gmtime())
    train_x = np.load('train_x_labeled.np.npy')
    train_y = np.load('train_ynp.npy')
    # print(train_x.shape)
    print(train_x[2,:])
    exit()

    idx = np.random.randint(train_count, size=M)
    train_x_part = train_x[idx,:]
    train_y_part = train_y[idx]

    # start = N*episode
    # end = start + N
    # train_x_part = train_x[start:end,:]
    # train_y_part = train_y[start:end]

    del train_x, train_y
    gc.collect()

    # import pickle
    print('start training')
    print(time.gmtime())
    model.fit(train_x_part, train_y_part, epochs=10, batch_size=32)

    # pickle.dump(clf, open('random_forest.mdl', 'wb'))
    # clf = pickle.load(open('random_forest.mdl', 'rb'))

    del train_x_part, train_y_part
    gc.collect()


    test_x = np.load('test_x_labeled.np.npy')
    fkck = np.zeros((test_x.shape[0], 1))
    test_x = np.hstack((fkck, test_x))

    print('start prediction')
    print(time.gmtime())
    results += model.predict(test_x, batch_size=32)[:,0]
    # results += model.predict(test_x)
    print(results.shape)
    np.save('results', results)
    # accuracy = roc_auc_score(train_y, predictions)
    # print('accuracy: ', accuracy)

    del test_x
    # del model
    gc.collect()


submission = pd.read_csv('sample_submission.csv')
submission['HasDetections'] = results/ episodes
submission.to_csv('tree_label_submission.csv', index=False)

print('\nDone.')