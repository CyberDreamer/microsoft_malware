import pandas as pd
import numpy as np
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from dtypes import dtypes
import time
from sklearn.preprocessing import LabelEncoder
from keras.models import Sequential
from keras.layers import Dense, Embedding

cat_columns = [key for key, value in dtypes.items() if value is 'category']
cat_types = {key: value for key, value in dtypes.items() if value is 'category'}
cat_columns.remove('MachineIdentifier')
cat_types.pop('MachineIdentifier', None)
# cat_columns.remove('HasDetections')

# print(cat_types)
# exit()

print('Load category features')
train = pd.read_csv('train.csv', dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)
# exit()
test  = pd.read_csv('test.csv',  dtype=cat_types, usecols=cat_columns, low_memory=True, nrows=None)

print('Transform category features')
col = 1
total_cols = len(cat_columns)
bias = np.uint16(1)

for usecol in cat_columns:
    print('column {}/{}'.format(col, total_cols))
    col+=1
    train[usecol] = train[usecol].astype('str')
    test[usecol] = test[usecol].astype('str')
    
    #Fit LabelEncoder
    le = LabelEncoder().fit(
            np.unique(train[usecol].unique().tolist()+
                      test[usecol].unique().tolist()))

    #At the end 0 will be used for dropped values
    train[usecol] = le.transform(train[usecol]) + bias
    test[usecol]  = le.transform(test[usecol]) + bias

    categories_count = train[usecol].max() - bias
    if test[usecol].max() - bias > categories_count:
        categories_count = test[usecol].max() - bias

    bias += categories_count
    print(bias)
    del le, usecol
    gc.collect()

print('test.shape: ', test.shape)
test = np.array(test, dtype=np.uint16)  
np.save('test_cat_np_x_2', test)  
del test
gc.collect()

print('train.shape: ', train.shape)
train = np.array(train, dtype=np.uint16)  
np.save('train_cat_np_x_2', train)  

