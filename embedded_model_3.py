import pandas as pd
import numpy as np
import lightgbm as lgb
#import xgboost as xgb
from scipy.sparse import vstack, csr_matrix, save_npz, load_npz
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.model_selection import StratifiedKFold
from sklearn.neural_network import MLPRegressor
#from sklearn.metrics import roc_auc_score
import gc
gc.enable()
from keras.models import Sequential, Model
from keras.layers import Dense, Embedding, Input, Reshape, Concatenate, Dropout
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score
from keras import optimizers

from dtypes import dtypes

import time

def build_model(train_cat, train_num):
    inputs = []
    embeddings = []
    train_x = []

    categories_count = train_cat.max()
    print('build net')
    vector_size = 200
    feature_size = 29

    input_layer = Input(shape=(feature_size,))
    embedding = Embedding(categories_count, vector_size, input_length=feature_size)(input_layer)
    embedding = Reshape(target_shape=(vector_size*feature_size,))(embedding)

    embedding = Dense(64, activation='relu')(embedding)
    embedding = Dropout(.15)(embedding)
    embedding = Dense(32, activation='relu')(embedding)
    embedding = Dropout(.15)(embedding)
    embedding = Dense(32, activation='relu')(embedding)

    inputs.append(input_layer)
    embeddings.append(embedding)
    train_x.append(train_cat)

    input_layer = Input(shape=(train_num.shape[1],))
    embedding = Dense(32, activation='relu')(input_layer)
    inputs.append(input_layer)
    embeddings.append(embedding)
    train_x.append(train_num)
    # NUMERIC
    x = Concatenate()(embeddings)
    x = Dense(16, activation='relu')(x)
    x = Dropout(.15)(x)
    x = Dense(8, activation='relu')(x)
    x = Dropout(.15)(x)
    x = Dense(8, activation='relu')(x)
    x = Dropout(.15)(x)
    x = Dense(8, activation='relu')(x)
    x = Dense(4, activation='relu')(x)
    output = Dense(1, activation='sigmoid')(x)
    model = Model(inputs, output)
    # optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
    optimizer = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)
    # optimizer = optimizers.SGD(lr=0.001, decay=0.0001)
    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])

    return model, train_x


train_count = 8921483
test_count = 7853253
# N = 2973827
episodes = 5
N = int(train_count / episodes)
M = 2 * N
print('step = ', N)
results = np.zeros(test_count)
for episode in range(episodes):
    print('start episode - {}/{}'.format(episode+1, episodes))
    print('load numpy arrays')
    print(time.gmtime())
    train_cat = np.load('train_cat_np_x_2.npy')
    train_num = np.load('train_num_np_x.npy')
    train_y = np.load('train_num_np_y.npy')

    # idx = np.random.randint(train_count, size=M)
    # train_x_part = train_x[idx,:]
    # train_y_part = train_y[idx]

    start = N*episode
    end = start + N
    train_cat_part = train_cat[start:end,:]
    train_num_part = train_num[start:end,:]
    train_y_part = train_y[start:end]

    del train_cat, train_num, train_y
    gc.collect()

    # import pickle
    print('start training')
    model, train_x = build_model(train_cat_part, train_num_part)
    print(time.gmtime())
    model.fit(train_x, train_y_part, batch_size=256, epochs=30)

    # pickle.dump(clf, open('random_forest.mdl', 'wb'))
    # clf = pickle.load(open('random_forest.mdl', 'rb'))

    del train_cat_part, train_num_part, train_x, train_y_part
    gc.collect()

    test_cat = np.load('test_cat_np_x_2.npy')
    test_num = np.load('test_num_np_x.npy')

    print('start prediction')
    print(time.gmtime())

    test_x = []
    test_x.append(test_cat)
    test_x.append(test_num)
    results += model.predict(test_x, batch_size=256)[:,0]

    print(results.shape)
    np.save('results', results)
    # accuracy = roc_auc_score(train_y, predictions)
    # print('accuracy: ', accuracy)

    del test_cat, test_num, test_x
    # del model
    gc.collect()


submission = pd.read_csv('sample_submission.csv')
submission['HasDetections'] = results/ episodes
submission.to_csv('nn_submission.csv', index=False)

print('Done.')